{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.1365333333333334,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.021333333333333333,
      "grad_norm": 0.4570862054824829,
      "learning_rate": 1.8e-05,
      "loss": 3.1394,
      "step": 10
    },
    {
      "epoch": 0.042666666666666665,
      "grad_norm": 0.6242455840110779,
      "learning_rate": 3.8e-05,
      "loss": 3.0785,
      "step": 20
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.7982631921768188,
      "learning_rate": 5.8e-05,
      "loss": 3.0424,
      "step": 30
    },
    {
      "epoch": 0.08533333333333333,
      "grad_norm": 0.6874598264694214,
      "learning_rate": 7.800000000000001e-05,
      "loss": 2.876,
      "step": 40
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.8677590489387512,
      "learning_rate": 9.8e-05,
      "loss": 2.776,
      "step": 50
    },
    {
      "epoch": 0.128,
      "grad_norm": 1.2642074823379517,
      "learning_rate": 0.000118,
      "loss": 2.7073,
      "step": 60
    },
    {
      "epoch": 0.14933333333333335,
      "grad_norm": 0.6708933711051941,
      "learning_rate": 0.000138,
      "loss": 2.6199,
      "step": 70
    },
    {
      "epoch": 0.17066666666666666,
      "grad_norm": 0.8581869006156921,
      "learning_rate": 0.00015800000000000002,
      "loss": 2.5792,
      "step": 80
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.5365809798240662,
      "learning_rate": 0.00017800000000000002,
      "loss": 2.5751,
      "step": 90
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.572228193283081,
      "learning_rate": 0.00019800000000000002,
      "loss": 2.5222,
      "step": 100
    },
    {
      "epoch": 0.23466666666666666,
      "grad_norm": 0.5109777450561523,
      "learning_rate": 0.0001986196319018405,
      "loss": 2.4521,
      "step": 110
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.5376030802726746,
      "learning_rate": 0.00019708588957055215,
      "loss": 2.4999,
      "step": 120
    },
    {
      "epoch": 0.2773333333333333,
      "grad_norm": 0.556172788143158,
      "learning_rate": 0.00019555214723926382,
      "loss": 2.5299,
      "step": 130
    },
    {
      "epoch": 0.2986666666666667,
      "grad_norm": 0.5517964959144592,
      "learning_rate": 0.00019401840490797546,
      "loss": 2.4731,
      "step": 140
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5147361755371094,
      "learning_rate": 0.00019248466257668713,
      "loss": 2.4823,
      "step": 150
    },
    {
      "epoch": 0.3413333333333333,
      "grad_norm": 0.5089366436004639,
      "learning_rate": 0.00019095092024539877,
      "loss": 2.5248,
      "step": 160
    },
    {
      "epoch": 0.3626666666666667,
      "grad_norm": 0.6514060497283936,
      "learning_rate": 0.00018941717791411044,
      "loss": 2.4773,
      "step": 170
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.5549396872520447,
      "learning_rate": 0.00018788343558282208,
      "loss": 2.4419,
      "step": 180
    },
    {
      "epoch": 0.4053333333333333,
      "grad_norm": 0.537999153137207,
      "learning_rate": 0.00018634969325153375,
      "loss": 2.4052,
      "step": 190
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 0.5690499544143677,
      "learning_rate": 0.00018481595092024542,
      "loss": 2.4496,
      "step": 200
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.5854473114013672,
      "learning_rate": 0.00018328220858895706,
      "loss": 2.3845,
      "step": 210
    },
    {
      "epoch": 0.4693333333333333,
      "grad_norm": 0.5543099045753479,
      "learning_rate": 0.00018174846625766873,
      "loss": 2.4518,
      "step": 220
    },
    {
      "epoch": 0.49066666666666664,
      "grad_norm": 0.5273390412330627,
      "learning_rate": 0.00018021472392638037,
      "loss": 2.4709,
      "step": 230
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.5209898948669434,
      "learning_rate": 0.00017868098159509204,
      "loss": 2.3986,
      "step": 240
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.56431645154953,
      "learning_rate": 0.0001771472392638037,
      "loss": 2.4172,
      "step": 250
    },
    {
      "epoch": 0.5546666666666666,
      "grad_norm": 0.5768306851387024,
      "learning_rate": 0.00017561349693251535,
      "loss": 2.4142,
      "step": 260
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.5509131550788879,
      "learning_rate": 0.00017407975460122702,
      "loss": 2.4725,
      "step": 270
    },
    {
      "epoch": 0.5973333333333334,
      "grad_norm": 0.5900889039039612,
      "learning_rate": 0.00017254601226993866,
      "loss": 2.4808,
      "step": 280
    },
    {
      "epoch": 0.6186666666666667,
      "grad_norm": 0.5341798663139343,
      "learning_rate": 0.00017101226993865033,
      "loss": 2.3847,
      "step": 290
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5358065366744995,
      "learning_rate": 0.000169478527607362,
      "loss": 2.4727,
      "step": 300
    },
    {
      "epoch": 0.6613333333333333,
      "grad_norm": 0.5480138063430786,
      "learning_rate": 0.00016794478527607364,
      "loss": 2.4349,
      "step": 310
    },
    {
      "epoch": 0.6826666666666666,
      "grad_norm": 0.5722423791885376,
      "learning_rate": 0.00016641104294478528,
      "loss": 2.4638,
      "step": 320
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.5455640554428101,
      "learning_rate": 0.00016487730061349695,
      "loss": 2.3851,
      "step": 330
    },
    {
      "epoch": 0.7253333333333334,
      "grad_norm": 0.5783746838569641,
      "learning_rate": 0.0001633435582822086,
      "loss": 2.4456,
      "step": 340
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.6180315017700195,
      "learning_rate": 0.00016180981595092026,
      "loss": 2.4613,
      "step": 350
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.6226357817649841,
      "learning_rate": 0.0001602760736196319,
      "loss": 2.4384,
      "step": 360
    },
    {
      "epoch": 0.7893333333333333,
      "grad_norm": 0.6390542387962341,
      "learning_rate": 0.00015874233128834357,
      "loss": 2.4321,
      "step": 370
    },
    {
      "epoch": 0.8106666666666666,
      "grad_norm": 0.6428000330924988,
      "learning_rate": 0.0001572085889570552,
      "loss": 2.4304,
      "step": 380
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.5391844511032104,
      "learning_rate": 0.00015567484662576688,
      "loss": 2.3839,
      "step": 390
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.5780192613601685,
      "learning_rate": 0.00015414110429447854,
      "loss": 2.4702,
      "step": 400
    },
    {
      "epoch": 0.8746666666666667,
      "grad_norm": 0.6852620244026184,
      "learning_rate": 0.00015260736196319019,
      "loss": 2.3864,
      "step": 410
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.5406144857406616,
      "learning_rate": 0.00015107361963190185,
      "loss": 2.4063,
      "step": 420
    },
    {
      "epoch": 0.9173333333333333,
      "grad_norm": 0.5937915444374084,
      "learning_rate": 0.0001495398773006135,
      "loss": 2.4197,
      "step": 430
    },
    {
      "epoch": 0.9386666666666666,
      "grad_norm": 0.5810943245887756,
      "learning_rate": 0.00014800613496932516,
      "loss": 2.4491,
      "step": 440
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5730466246604919,
      "learning_rate": 0.00014647239263803683,
      "loss": 2.3897,
      "step": 450
    },
    {
      "epoch": 0.9813333333333333,
      "grad_norm": 0.58671635389328,
      "learning_rate": 0.00014493865030674847,
      "loss": 2.4513,
      "step": 460
    },
    {
      "epoch": 1.0042666666666666,
      "grad_norm": 0.5954777002334595,
      "learning_rate": 0.00014340490797546014,
      "loss": 2.5654,
      "step": 470
    },
    {
      "epoch": 1.0256,
      "grad_norm": 0.6339678168296814,
      "learning_rate": 0.00014187116564417178,
      "loss": 2.3626,
      "step": 480
    },
    {
      "epoch": 1.0469333333333333,
      "grad_norm": 0.6588530540466309,
      "learning_rate": 0.00014033742331288345,
      "loss": 2.3977,
      "step": 490
    },
    {
      "epoch": 1.0682666666666667,
      "grad_norm": 0.6676056981086731,
      "learning_rate": 0.00013880368098159512,
      "loss": 2.3756,
      "step": 500
    },
    {
      "epoch": 1.0896,
      "grad_norm": 0.6387247443199158,
      "learning_rate": 0.00013726993865030676,
      "loss": 2.3325,
      "step": 510
    },
    {
      "epoch": 1.1109333333333333,
      "grad_norm": 0.6744348406791687,
      "learning_rate": 0.0001357361963190184,
      "loss": 2.3472,
      "step": 520
    },
    {
      "epoch": 1.1322666666666668,
      "grad_norm": 0.6326634883880615,
      "learning_rate": 0.00013420245398773005,
      "loss": 2.3589,
      "step": 530
    },
    {
      "epoch": 1.1536,
      "grad_norm": 0.6840425133705139,
      "learning_rate": 0.00013266871165644171,
      "loss": 2.4233,
      "step": 540
    },
    {
      "epoch": 1.1749333333333334,
      "grad_norm": 0.6939998865127563,
      "learning_rate": 0.00013113496932515338,
      "loss": 2.3396,
      "step": 550
    },
    {
      "epoch": 1.1962666666666666,
      "grad_norm": 0.7292037606239319,
      "learning_rate": 0.00012960122699386502,
      "loss": 2.4312,
      "step": 560
    },
    {
      "epoch": 1.2176,
      "grad_norm": 0.7009084820747375,
      "learning_rate": 0.0001280674846625767,
      "loss": 2.3882,
      "step": 570
    },
    {
      "epoch": 1.2389333333333332,
      "grad_norm": 0.6426689624786377,
      "learning_rate": 0.00012653374233128833,
      "loss": 2.3765,
      "step": 580
    },
    {
      "epoch": 1.2602666666666666,
      "grad_norm": 0.6551823616027832,
      "learning_rate": 0.000125,
      "loss": 2.369,
      "step": 590
    },
    {
      "epoch": 1.2816,
      "grad_norm": 0.684775173664093,
      "learning_rate": 0.00012346625766871167,
      "loss": 2.4067,
      "step": 600
    },
    {
      "epoch": 1.3029333333333333,
      "grad_norm": 0.6127550601959229,
      "learning_rate": 0.00012193251533742331,
      "loss": 2.468,
      "step": 610
    },
    {
      "epoch": 1.3242666666666667,
      "grad_norm": 0.6685969829559326,
      "learning_rate": 0.00012039877300613498,
      "loss": 2.3714,
      "step": 620
    },
    {
      "epoch": 1.3456000000000001,
      "grad_norm": 0.7122732996940613,
      "learning_rate": 0.00011886503067484662,
      "loss": 2.3795,
      "step": 630
    },
    {
      "epoch": 1.3669333333333333,
      "grad_norm": 0.6579571962356567,
      "learning_rate": 0.00011733128834355829,
      "loss": 2.3508,
      "step": 640
    },
    {
      "epoch": 1.3882666666666665,
      "grad_norm": 0.6941933631896973,
      "learning_rate": 0.00011579754601226996,
      "loss": 2.3853,
      "step": 650
    },
    {
      "epoch": 1.4096,
      "grad_norm": 0.6681801080703735,
      "learning_rate": 0.0001142638036809816,
      "loss": 2.3587,
      "step": 660
    },
    {
      "epoch": 1.4309333333333334,
      "grad_norm": 0.6201761960983276,
      "learning_rate": 0.00011273006134969326,
      "loss": 2.3291,
      "step": 670
    },
    {
      "epoch": 1.4522666666666666,
      "grad_norm": 0.690030038356781,
      "learning_rate": 0.0001111963190184049,
      "loss": 2.4058,
      "step": 680
    },
    {
      "epoch": 1.4736,
      "grad_norm": 0.7483643293380737,
      "learning_rate": 0.00010966257668711657,
      "loss": 2.3922,
      "step": 690
    },
    {
      "epoch": 1.4949333333333334,
      "grad_norm": 0.7160443067550659,
      "learning_rate": 0.00010812883435582823,
      "loss": 2.3714,
      "step": 700
    },
    {
      "epoch": 1.5162666666666667,
      "grad_norm": 0.646649181842804,
      "learning_rate": 0.00010659509202453988,
      "loss": 2.3381,
      "step": 710
    },
    {
      "epoch": 1.5375999999999999,
      "grad_norm": 0.6556049585342407,
      "learning_rate": 0.00010506134969325154,
      "loss": 2.3356,
      "step": 720
    },
    {
      "epoch": 1.5589333333333333,
      "grad_norm": 0.632619321346283,
      "learning_rate": 0.00010352760736196319,
      "loss": 2.3428,
      "step": 730
    },
    {
      "epoch": 1.5802666666666667,
      "grad_norm": 0.7208462953567505,
      "learning_rate": 0.00010199386503067485,
      "loss": 2.3415,
      "step": 740
    },
    {
      "epoch": 1.6016,
      "grad_norm": 0.7310654520988464,
      "learning_rate": 0.00010046012269938651,
      "loss": 2.3677,
      "step": 750
    },
    {
      "epoch": 1.6229333333333333,
      "grad_norm": 0.7552948594093323,
      "learning_rate": 9.892638036809816e-05,
      "loss": 2.4031,
      "step": 760
    },
    {
      "epoch": 1.6442666666666668,
      "grad_norm": 0.7557883858680725,
      "learning_rate": 9.739263803680982e-05,
      "loss": 2.3854,
      "step": 770
    },
    {
      "epoch": 1.6656,
      "grad_norm": 0.7001786828041077,
      "learning_rate": 9.585889570552147e-05,
      "loss": 2.373,
      "step": 780
    },
    {
      "epoch": 1.6869333333333332,
      "grad_norm": 0.7664140462875366,
      "learning_rate": 9.432515337423313e-05,
      "loss": 2.3444,
      "step": 790
    },
    {
      "epoch": 1.7082666666666668,
      "grad_norm": 0.68214350938797,
      "learning_rate": 9.279141104294478e-05,
      "loss": 2.3452,
      "step": 800
    },
    {
      "epoch": 1.7296,
      "grad_norm": 0.6240657567977905,
      "learning_rate": 9.125766871165644e-05,
      "loss": 2.3927,
      "step": 810
    },
    {
      "epoch": 1.7509333333333332,
      "grad_norm": 0.7061984539031982,
      "learning_rate": 8.972392638036811e-05,
      "loss": 2.3698,
      "step": 820
    },
    {
      "epoch": 1.7722666666666667,
      "grad_norm": 0.7295087575912476,
      "learning_rate": 8.819018404907976e-05,
      "loss": 2.3693,
      "step": 830
    },
    {
      "epoch": 1.7936,
      "grad_norm": 0.7887717485427856,
      "learning_rate": 8.665644171779142e-05,
      "loss": 2.4086,
      "step": 840
    },
    {
      "epoch": 1.8149333333333333,
      "grad_norm": 0.6851483583450317,
      "learning_rate": 8.512269938650307e-05,
      "loss": 2.3878,
      "step": 850
    },
    {
      "epoch": 1.8362666666666667,
      "grad_norm": 0.6875462532043457,
      "learning_rate": 8.358895705521473e-05,
      "loss": 2.3483,
      "step": 860
    },
    {
      "epoch": 1.8576000000000001,
      "grad_norm": 0.7833808660507202,
      "learning_rate": 8.205521472392638e-05,
      "loss": 2.4131,
      "step": 870
    },
    {
      "epoch": 1.8789333333333333,
      "grad_norm": 0.6580358147621155,
      "learning_rate": 8.052147239263804e-05,
      "loss": 2.3785,
      "step": 880
    },
    {
      "epoch": 1.9002666666666665,
      "grad_norm": 0.6821941137313843,
      "learning_rate": 7.898773006134969e-05,
      "loss": 2.3262,
      "step": 890
    },
    {
      "epoch": 1.9216,
      "grad_norm": 0.7307356595993042,
      "learning_rate": 7.745398773006135e-05,
      "loss": 2.3543,
      "step": 900
    },
    {
      "epoch": 1.9429333333333334,
      "grad_norm": 0.69510817527771,
      "learning_rate": 7.5920245398773e-05,
      "loss": 2.3678,
      "step": 910
    },
    {
      "epoch": 1.9642666666666666,
      "grad_norm": 0.6901982426643372,
      "learning_rate": 7.438650306748467e-05,
      "loss": 2.3862,
      "step": 920
    },
    {
      "epoch": 1.9856,
      "grad_norm": 0.7477316856384277,
      "learning_rate": 7.285276073619633e-05,
      "loss": 2.3897,
      "step": 930
    },
    {
      "epoch": 2.0085333333333333,
      "grad_norm": 0.6537507772445679,
      "learning_rate": 7.131901840490798e-05,
      "loss": 2.5164,
      "step": 940
    },
    {
      "epoch": 2.0298666666666665,
      "grad_norm": 0.7332677245140076,
      "learning_rate": 6.978527607361964e-05,
      "loss": 2.3088,
      "step": 950
    },
    {
      "epoch": 2.0512,
      "grad_norm": 0.822270929813385,
      "learning_rate": 6.825153374233129e-05,
      "loss": 2.2865,
      "step": 960
    },
    {
      "epoch": 2.0725333333333333,
      "grad_norm": 0.7434226870536804,
      "learning_rate": 6.671779141104295e-05,
      "loss": 2.2934,
      "step": 970
    },
    {
      "epoch": 2.0938666666666665,
      "grad_norm": 0.7367339134216309,
      "learning_rate": 6.51840490797546e-05,
      "loss": 2.3167,
      "step": 980
    },
    {
      "epoch": 2.1152,
      "grad_norm": 0.7248939275741577,
      "learning_rate": 6.365030674846626e-05,
      "loss": 2.2574,
      "step": 990
    },
    {
      "epoch": 2.1365333333333334,
      "grad_norm": 0.7549430727958679,
      "learning_rate": 6.211656441717791e-05,
      "loss": 2.3668,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 1404,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.6262184550426214e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
